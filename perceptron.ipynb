{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Layer Perceptron for Character Recognition\n",
    "\n",
    "## By: Jeremy Rico and David Walsh\n",
    "\n",
    "This program creates 26 individual perceptrons, one for each letter of the alphabet. The perceptrons are trained on the training set from dataset.py and tested on the test set from the same file. in the training and the test set, each letter is represented as a 5x7 dot matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset\n",
    "#path = \"/Users/DanielWalsh/Desktop/dataset.py\"\n",
    "#open(path).readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset represents each character as a dot matrix, we must first convert each matrix in the dataset into a binary vector. Then we combine the vectors to create the final training set as a binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dot matrix to binary vector\n",
    "def char2vec(char):\n",
    "    return [\n",
    "        0 if pixel == '.' else 1\n",
    "        for line in char\n",
    "        for pixel in line\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "char2vec() converts each 5x7 dot matrix into a binary vector\n",
    "\n",
    "'#' = 1\n",
    "\n",
    "'.' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert entire dataset to np array with leading 1 for w0\n",
    "# also appends 0 to each row later to be used for storing expected output\n",
    "def mat2np_arr_TRAIN(data):\n",
    "    set = []\n",
    "    for elem in data:\n",
    "        row = char2vec(elem) # convert 5x7 dot matrix to linear vector\n",
    "        row.insert(0,1) # preppend each row with a 1 for w0\n",
    "        row.append(0) # append with a 0 for expected ouput\n",
    "        set.append(row)\n",
    "\n",
    "    return np.array(set) #convert to np array and return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mat2np_arr_TRAIN does a few important things:\n",
    "\n",
    "1. it calls char2vec() to create a binary vector \n",
    " \n",
    "    (#, ., #) => (1, 0, 1)\n",
    " \n",
    " \n",
    "2. it prepends that vector with a 1 to account for w0\n",
    "    \n",
    "    (1, 0, 1) => (1, 1, 0, 1)\n",
    " \n",
    " \n",
    "3. it appends the vector with a 0 which will hold the value for expected output\n",
    "    \n",
    "    (1, 1, 0, 1) => (1, 1, 0, 1, 0)\n",
    " \n",
    " \n",
    "4. it converts the final matrix into an np matrix\n",
    "\n",
    "**This function is ONLY to be used for the training set, as the test set is not to have a column for expected output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert entire dataset to np array with leading 1 for w0\n",
    "# DOES NOT append a 0 for expected input\n",
    "def mat2np_arr_TEST(data):\n",
    "    set = []\n",
    "    for elem in data:\n",
    "        row = char2vec(elem) # convert 5x7 dot matrix to linear vector\n",
    "        row.insert(0,1) # preppend each row with a 1 for w0\n",
    "        set.append(row)\n",
    "\n",
    "    return np.array(set) #convert to np array and return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mat2np_arr_TEST() does everything that mat2np_arr_TRAIN does except append each row with a 0 for the expected output. Otherwise, it is exactly the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Class Definitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization:\n",
    "\n",
    "\n",
    "Each perceptron is initized with the following:\n",
    "1. The training set which is copied using np.copy()\n",
    "2. A set of random weights between -1 and 1\n",
    "3. A name (Ex: Perceptron 'A', Perceptron 'B')\n",
    "4. Threshold value to be used for activation (Default set to 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    # initializer\n",
    "    # matrix of inputs must have leading ones and expected output values\n",
    "    def __init__(self, input_mat, name, thresh = 0.0):\n",
    "        self.input_mat = np.copy(input_mat)\n",
    "        # initialize random weights\n",
    "        np.random.seed(1)\n",
    "        self.weights = 2 * np.random.random_sample(len(self.input_mat[0]) - 1) - 1\n",
    "        self.name = name\n",
    "        self.thres = thresh # default threshold set to 0 for activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function:\n",
    "\n",
    "Simply takes the dot product of the input vector (without the expected output value) and the weights.\n",
    "\n",
    "Returns 1 if the dot value if greater than the threshold value (0.0). This means the neuron has activated or \"fired\"\n",
    "\n",
    "Otherwise returns 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # activation function\n",
    "    def activation_func(self, inputs, weights):\n",
    "        total_activation = np.dot(inputs, weights)\n",
    "        return 1.0 if total_activation >= self.thres else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions function:\n",
    "\n",
    "This function loops through each element in the training set. For each element (or letter) it calls the activation function to make a prediction based on the current weights. Each predictions is appended to a list called predictions. The function then returns this list.\n",
    "\n",
    "For example, for the 'A' perceptron a correct prediction list would have a 1.0 in index 0 and a 0.0 in all other indexes. So the return value would look like this:\n",
    "\n",
    "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # prediction for each character stored in a list\n",
    "    def predict(self, matrix, weights):\n",
    "        predictions = []\n",
    "        for i in range(len(matrix)):\n",
    "            prediction = self.activation_func(matrix[i][:-1], weights)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy function:\n",
    "\n",
    "The accuracy function calculates the accuracy of our predictions by comparing them to the expected output. It returns the percentage of correct predictions the perceptrons has made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # accuracy function to calculate the percentage of correct predictions made\n",
    "    def accuracy(self, expected, predictions):\n",
    "        num_correct = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] == expected[i]: num_correct += 1.0\n",
    "\n",
    "        return num_correct/float(len(expected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function:\n",
    "\n",
    "This is the big boy. It is used to adjust the weights of each perceptron according to the Perceptron LEarning Algorithm.\n",
    "\n",
    "First we define and set default values for the following parameters:\n",
    "1. max_epoch: maximum number of EPOCHS; default set to 1000\n",
    "2. l_rate: learning rate ETA; default value set to 0.1 (found to be the best value via trial and error)\n",
    "3. stop_early: stop function if we have reached 100% accuracy\n",
    "4. do_print: prints out important values such as errors made and current accuracy\n",
    "\n",
    "We also define a new class attribute, errors_made. This will store the number of errors made by the perceptron during each EPOCH. It will be later used to create error plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each EPOCH we will:\n",
    "1. initialize the number of errors as 0\n",
    "2. make predictions with the current weights\n",
    "3. calculate the current accuracy of those predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have reached 100% accuracy:\n",
    "1. append errors_made with a 0 for plotting purposes\n",
    "2. print out final calcualtions\n",
    "3. break from the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise for each element (letter) in the training set we will:\n",
    "1. calculate the error using the following equation\n",
    "\n",
    "    **error = expected output - prediction**\n",
    "    \n",
    "    and increment the number of errors if error != 0\n",
    "    \n",
    "2. For each weight in the weight array we will update its value using the following eqation\n",
    "    \n",
    "    **new Weight = old Weight + (learning rate * error * input value at that index)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we append the number of errors made at that epoch to errors_made and print information if do_print is set to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # function used to train the perceptron\n",
    "    def train(self, max_epoch = 1000, l_rate = 0.1, stop_early = True, do_print = False):\n",
    "\n",
    "        if do_print: print('\\nTRAINING PERCEPTRON: %s' % self.name)\n",
    "            \n",
    "        self.errors_made = []    \n",
    "        for epoch in range(max_epoch):\n",
    "\n",
    "            num_errors = 0\n",
    "            self.preds = self.predict(self.input_mat, self.weights)\n",
    "            cur_acc = self.accuracy(self.input_mat[:, -1], self.preds)\n",
    "    \n",
    "            # if we have reached 100% accuracy we can stop early\n",
    "            if cur_acc == 1.0 and stop_early:\n",
    "                self.errors_made.append(num_errors)\n",
    "                if do_print:\n",
    "                    print(\"\\nEpoch %d \\nErrors made: %d\" % (epoch + 1, num_errors))\n",
    "                    print(\"Accuracy: %0.5f\" %cur_acc)\n",
    "                    print(\"Weights: \", self.weights)\n",
    "                    print(\"Predictions: \", self.preds)\n",
    "                break\n",
    "\n",
    "            for i in range(len(self.input_mat)):\n",
    "                # calculate error (+1 or -1 mean wrong prediction; 0 means correct)\n",
    "                error = self.input_mat[i][-1] - self.preds[i]\n",
    "                # if prediction was wrong increment number of errors\n",
    "                if error != 0: num_errors += 1\n",
    "\n",
    "                # update weights using eta(?) equation\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] = self.weights[j] + (l_rate * error * self.input_mat[i][j])\n",
    "\n",
    "            self.errors_made.append(num_errors)\n",
    "            if do_print:\n",
    "                print(\"\\nEpoch %d \\nErrors made: %d\" % (epoch + 1, num_errors))\n",
    "                print(\"Accuracy: %0.5f\" % cur_acc)\n",
    "                print(\"Weights: \", self.weights)\n",
    "                print(\"Predictions: \", self.preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function:\n",
    "\n",
    "Only to be used to test the finalizes weights.\n",
    "Simply calls the activation function and returns either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # test function works with only one letter at a time\n",
    "    def test(self, test_matrix):\n",
    "        return self.activation_func(test_matrix, self.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Error function:\n",
    "\n",
    "Uses matplotlib to plot the errors_made list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # plot error function\n",
    "    def plot_error(self):\n",
    "        epochs = np.arange(0, len(self.errors_made))\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, self.errors_made, 'b-')\n",
    "        plt.title(\"Training Error for \" + self.name)\n",
    "        plt.xlabel(\"EPOCH\")\n",
    "        plt.ylabel(\"# of Errors Made\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEGIN MAIN CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Training set and Test set using conversion functions\n",
    "\n",
    "dict: sed solely for ease of use when testing different perceptrons\n",
    "\n",
    "dict_: is used in the training loop to name each perceptron after it's letter\n",
    "\n",
    "perceptrons: a list to be used to store each perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat2np_arr prepends a 1 and appends a 0 to each column of the training data\n",
    "TRAINING_SET = mat2np_arr_TRAIN(dataset.TRAINING_DATA)\n",
    "TEST_SET = mat2np_arr_TEST(dataset.TEST_DATA)\n",
    "dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8,\n",
    " 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17,\n",
    " 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
    "dict_ = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "perceptrons = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "Copies training set and changes the appropriate expected output slot to 1.0.\n",
    "\n",
    "Then trains a perceptron based on the data and appends it to our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Perceptron' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-008e1596d53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mTRAIN_SET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_SET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set do_print to true for errors and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mperceptrons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Perceptron' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "# Trains all perceptrons and appends them to a list\n",
    "for i in range(len(TRAINING_SET)):\n",
    "    TRAIN_SET = np.copy(TRAINING_SET)\n",
    "    TRAIN_SET[i][-1] = 1\n",
    "    p = Perceptron(TRAIN_SET, dict_[i])\n",
    "    p.train(do_print = False) # set do_print to true for errors and accuracy\n",
    "    perceptrons.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting plots:\n",
    "\n",
    "We found the letter A to be the most consistently predicatable and therefore linearly seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptrons[dict['A']].plot_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The letter W would converge. However, during testing the perceptron would fire for multiple other letters as well as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptrons[dict['W']].plot_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The letter E was found to be not linearly seperable. The plot of errors was never a smooth curve and the perceptron almost never predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptrons[dict['E']].plot_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Loop:\n",
    "\n",
    "Nested for loop to test each perceptron against each character in the test set. Prints out a message for what Perceptron it is currently testing, if the neuron activates, and for which character it activated for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "# Tests every perceptron against every test character\n",
    "# Prints message if the perceptron fires\n",
    "for i in range(len(perceptrons)):\n",
    "    print(\"\\nTesting perceptron: %s\" % perceptrons[i].name)\n",
    "\n",
    "    for j in range(len(TEST_SET)):\n",
    "        prediction = perceptrons[i].test(TEST_SET[j])\n",
    "        if prediction == 1:\n",
    "            print(\"Activation: \", dict_[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have found the following characters to be consistently linearly seperable: \n",
    "\n",
    "A, C, F, H, I, K, L, P, T, V, X, Y\n",
    "\n",
    "The following predict correctly, but other neurons also fire on the same perceptron:\n",
    "\n",
    "B, O, U, W, Z\n",
    "\n",
    "And the following we found to be non linearly seperable:\n",
    "\n",
    "D, E, G, J, M, N, Q, R, S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
